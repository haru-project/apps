# Persistent data folder
ROS_DATA=../data/people_ros_persistent_data
# Path to colcon ws to be mounted on developper container
# the default value assumes that the people compose file is installed at COLCON_WS/src/strawberry-ros-people/docker, which is the usual
COLCON_WS=../../..

# DISPLAY / GPU
DISPLAY=${DISPLAY:-=:0}
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=all
XAUTH=/tmp/.docker.xauth
LIBGL_ALWAYS_SOFTWARE=1

# ROS
ROS_DOMAIN_ID=0
RMW_IMPLEMENTATION=rmw_fastrtps_cpp
FASTDDS_BUILTIN_TRANSPORTS=UDPv4

# ************ #
# FACES MODULE
# ************ #

FACES_IMAGE_TOPIC=/azure_kinect/rgb/image_raw/compressed

# Component enable/disable arguments
FACES_LAUNCH_CROPPER=true
FACES_LAUNCH_STABILIZER=true
FACES_LAUNCH_GENDER=true
FACES_LAUNCH_EMOTION=true
FACES_LAUNCH_LANDMARKS=true
FACES_LAUNCH_IDENTITIES_RECOGNITOR=true
FACES_LAUNCH_IDENTITIES_TRAINER=true
FACES_LAUNCH_MERGER=true
FACES_LAUNCH_MERGER_API=true

# Common parameters
FACES_RESPAWN=true
FACES_ENABLE_RQT_VIEW=true
FACES_LOG_LEVEL=INFO

# Face cropper parameters
FACES_ENABLE_DEBUG_FACE_CROPPER_DEBUG_IMAGE=false
FACES_BASE_PATH=/.ros/strawberry_ros_faces_module/data/data/sw_faces_crops/
FACES_THRESHOLD_YOLO=0.7
FACES_MAX_NUMBER_FACES=8
FACES_ENABLE_FACES_CROPPER=true
FACES_FACES_CROPPER_MODEL=yolo
FACES_INSIGHTFACE_PACK_NAME=buffalo_l
FACES_INSIGHTFACE_DET_SIZE=[960, 960]
FACES_INSIGHTFACE_MAX_SIZE=1920
FACES_INSIGHTFACE_DEVICE=cuda
FACES_INSIGHTFACE_DET_SCORE_THRESHOLD=0.7

# Face tracker parameters
FACES_ENABLE_FACES_TRACKER=true
FACES_INITIAL_ID_TRACKED=1
FACES_TIMEOUT_TRACKER=5.0
FACES_EMBEDDING_THRESHOLD=0.1
FACES_EMBEDDING_WEIGHT=0.2
FACES_ENABLE_DEBUG_TRACKER=false

# Face gender parameters
FACES_ENABLE_FACES_GENDER=false
FACES_ENABLE_DEBUG_FACE_GENDER_IMAGE=false
FACES_MODEL_FILE_GENDER=/.ros/strawberry_ros_faces_module/data/data/sw_faces_gender/models/gender_model.h5
FACES_MODEL_FILE_DICTIONARY_GENDER=/.ros/strawberry_ros_faces_module/data/data/sw_faces_gender/models/gender_labels_dictionary.pkl
FACES_GENDER_STABLE_PREDICTION_THRESHOLD=5
FACES_GENDER_INITIAL_CHECK_INTERVAL=0.1
FACES_GENDER_MAX_CHECK_INTERVAL=60.0
FACES_GENDER_INTERVAL_GROWTH_FACTOR=1.5
FACES_GENDER_ENABLE_INFINITE_STABLE=true
FACES_GENDER_INFINITE_STABLE_THRESHOLD=10

# Face emotions parameters
FACES_ENABLE_FACES_EMOTION=false
FACES_ENABLE_DEBUG_EMOTIONS_IMAGE=false
FACES_MODEL_FILE_EMOTION=/.ros/strawberry_ros_faces_module/data/data/sw_faces_emotion/models/emotion_model.h5
FACES_MODEL_FILE_DICTIONARY_EMOTION=/.ros/strawberry_ros_faces_module/data/data/sw_faces_emotion/models/emotion_labels_dictionary.pkl

# MediaPipe landmarks parameters
FACES_ENABLE_LANDMARKS=true
FACES_ENABLE_GAZE_ESTIMATION=true
FACES_ENABLE_DEBUG_LANDMARKS_IMAGE=false
FACES_MIN_DETECTION_CONFIDENCE=0.5
FACES_MAX_NUM_FACES=1
FACES_STATIC_IMAGE_MODE=false
FACES_REFINE_LANDMARKS=true
FACES_GAZE_THRESHOLD=0.3
FACES_GAZE_X_SCORE_MULTIPLIER=4.0
FACES_GAZE_Y_SCORE_MULTIPLIER=4.0

# Face recognition predictor parameters
FACES_ENABLE_FACES_RECOGNITOR=true
FACES_ONLINE_TRAINING=true
FACES_ENABLE_IDENTITIES_RECOGNITOR_DEBUG_IMAGE=false
FACES_MODEL_FILE_RECOGNITION=.ros/strawberry_ros_faces_module/data/data/sw_faces_recognitor/model/rf_model.pkl
FACES_RECOGNITION_THRESHOLD=0.5
FACES_IDENTIFY_UNKNOWN=false
FACES_ACTIVATE_AUTO_IMPROVEMENT=false
FACES_MAX_BUFFER_SIZE=20
FACES_DISTANCE_THRESHOLD_FOR_AUTO_IMPROVEMENT=0.1
FACES_REQUIRED_CONSIST_FRAMES=200
FACES_INTERVAL_AUTOIMP=200
FACES_LEARNING_DATASET_PATH_CSV=~/.ros/strawberry_ros_faces_module/data/face_learning/learning_dataset.csv
FACES_ENABLE_DEBUG_FACE_LEARNING_DEBUG_IMAGE=true
FACES_SAVE_CROP_IMAGES=true
FACES_RECOGNITION_STABLE_PREDICTION_THRESHOLD=5
FACES_RECOGNITION_INITIAL_CHECK_INTERVAL=0.1
FACES_RECOGNITION_MAX_CHECK_INTERVAL=60.0
FACES_RECOGNITION_INTERVAL_GROWTH_FACTOR=1.5
FACES_RECOGNITION_ENABLE_INFINITE_STABLE=false
FACES_RECOGNITION_INFINITE_STABLE_THRESHOLD=10

# Face recognition trainer parameters
FACES_MODEL_FILE_HASH_RECOGNITION=.ros/strawberry_ros_faces_module/data/data/sw_faces_recognitor/known_people_dataset_hash.pkl
FACES_DATASET_PATH_RECOGNITION_CSV=.ros/strawberry_ros_faces_module/data/data/sw_faces_recognitor/known_people_dataset.csv
FACES_SINGLE_MODEL=true
FACES_TRAINER_DATASET_BASE_FOLDER=~/.ros/strawberry_ros_faces_module/data/data/sw_faces_recognitor
FACES_TRAINER_RECOGNITION_MODEL_TYPE=rf
FACES_TRAINER_AUTO_TRAIN_ON_STARTUP=false
FACES_TRAINER_INSIGHTFACE_PACK_NAME=buffalo_l
FACES_TRAINER_INSIGHTFACE_DEVICE=cuda
FACES_TRAINER_INSIGHTFACE_MAX_IMAGES_PER_PERSON=200
FACES_TRAINER_INSIGHTFACE_MIN_IMAGES_PER_PERSON=1
FACES_TRAINER_INSIGHTFACE_RECOGNITION_THRESHOLD=0.35
FACES_TRAINER_INSIGHTFACE_BASE_ARTIFACTS_DIR=~/.ros/strawberry_ros_faces_module/data/data/sw_faces_recognitor/insightface_artifacts

# Faces merger parameters
FACES_SYNC_USING_STAMP=true
FACES_CROPS_TOPIC=/faces/crops/tracked
FACES_IDENTITIES_TOPIC=/faces/identities/recognitor/results
FACES_GENDERS_TOPIC=/faces/genders/results
FACES_EMOTIONS_TOPIC=/faces/emotions/results
FACES_LANDMARKS_TOPIC=/faces/landmarks/results

# Cache Parameters
FACES_CROPPS_CACHE_DURATION=4.0
FACES_CROPPS_CACHE_SIZE=20
FACES_IDENTITIES_CACHE_DURATION=4.0
FACES_IDENTITIES_CACHE_SIZE=20
FACES_GENDERS_CACHE_DURATION=4.0
FACES_GENDER_CACHE_SIZE=20
FACES_EMOTIONS_CACHE_DURATION=4.0
FACES_EMOTIONS_CACHE_SIZE=20
FACES_LANDMARKS_CACHE_DURATION=4.0
FACES_LANDMARKS_CACHE_SIZE=20

# Hold Time Parameters
FACES_IDENTITY_HOLD_TIME=4.0
FACES_GENDER_HOLD_TIME=4.0
FACES_EMOTION_HOLD_TIME=4.0
FACES_LANDMARKS_HOLD_TIME=4.0

# Synchronization Parameters
FACES_SYNC_THRESHOLD=4.0


# *************** #
# LEARNING SERVICE
# *************** #

# Face Learning Service Parameters
# Learning mode: 0 = name-based learning, 1 = ID-based learning
LEARNING_MODE=1
LEARNING_PERSON_NAME=nabil
LEARNING_PERSON_ID=1
LEARNING_NUMBER_OF_SAMPLES=50


# **************** #
# HANDS MODULE
# **************** #

# Virtual environment path
# Commented out so ti uses defautl value
# HANDS_VENV_PATH=/home/haru/haru_ws/install/strawberry_ros_hands/share/strawberry_ros_hands/venv_ros_hands

# General hands detection parameters
HANDS_MAX_NUM_HANDS=2
HANDS_MIN_DETECTION_CONFIDENCE=0.6
HANDS_MIN_TRACKING_CONFIDENCE=0.6

# General system parameters
HANDS_LOOP_RATE=8
HANDS_VIEW_IMAGES=false
HANDS_RUN_CAMERA=false
HANDS_CAMERA_NAME=/azure_kinect/rgb
HANDS_RESPAWN=true

# Left hand gesture recognition parameters
HANDS_CONSECUTIVE_PREDICTIONS_THRESHOLD_LEFT=3
#HANDS_MODEL_FILE_LEFT=/home/haru/haru_ws/install/strawberry_ros_hands/share/strawberry_ros_hands/models/default_jankenpon.joblib

# Right hand gesture recognition parameters
HANDS_CONSECUTIVE_PREDICTIONS_THRESHOLD_RIGHT=3
#HANDS_MODEL_FILE_RIGHT=/home/haru/haru_ws/install/strawberry_ros_hands/share/strawberry_ros_hands/models/default_jankenpon.joblib

# Gesture prediction parameters
HANDS_MIN_PREDICTION_CONFIDENCE=0.5
HANDS_TIME_INTERVAL_HAND_COMBINATION=0.10

# Debug and visualization parameters
HANDS_PUBLISH_GESTURE_DEBUG_IMAGE=false
HANDS_PUBLISH_ORIGINAL_IMAGE=false

# Status monitoring parameters
HANDS_ENABLE_HANDS_DETECTION=true
HANDS_ENABLE_DEBUG_HANDS_IMAGE=true


# ******************** #
# VISUALIZATION MODULE
# ******************** #

# RViz2 visualization parameters
VIZ_LAUNCH_RVIZ=true
VIZ_RVIZ_CONFIG=/opt/ros/jazzy/share/strawberry_ros_people/rviz/people_pipeline_rviz2_view.rviz
VIZ_RESPAWN=false


# ************* #
# PEOPLE MODULE
# ************* #

# Workspace boundaries
PEOPLE_WS_X_MAX=5.0
PEOPLE_WS_X_MIN=-5.0
PEOPLE_WS_Y_MAX=5.0
PEOPLE_WS_Y_MIN=-5.0
PEOPLE_WS_Z_MAX=5.0
PEOPLE_WS_Z_MIN=-5.0

# Skeletons cache and filtering parameters
PEOPLE_SKELETONS_CACHE_DURATION=1.0
PEOPLE_SKELETONS_CACHE_SIZE=100
PEOPLE_SKELETONS_MIN_NUM_PER_ID=2

# Association factors
PEOPLE_HANDS_ASSOCIATION_FACTOR=1.0
PEOPLE_FACES_ASSOCIATION_FACTOR=1.0

# Synchronization parameters
PEOPLE_SYNC_USING_STAMP=true

# Topic configuration
PEOPLE_SKELETONS_TOPIC=/strawberry/azure/skeletons
PEOPLE_FACES_TOPIC=/faces/results
PEOPLE_HANDS_TOPIC=/strawberry/hands_with_gestures
PEOPLE_SOUND_TOPIC=/idmind_tabletop/sound_localization
PEOPLE_SPEECH_TOPIC=/haru_speech/speech_to_text/result
PEOPLE_VAD_TOPIC=/haru_speech/speech_to_text/status
PEOPLE_WUW_TOPIC=/idmind_tabletop/wake_up_word

# VAD and speech processing parameters
PEOPLE_VAD_HOLD_TIME=1.0

# ======================
# Monitor launcher args
# ======================

# Absolute Python path for monitor venv used by compose.
# WARNING: Changing this may break GPU/NVML detection if the nodes fall back
# to system Python without required packages. Keep in sync with image layout.
# commented out to use default
#MON_VENV_PATH=/home/haru/haru_ws/install/strawberry_resource_monitor/share/strawberry_resource_monitor/venv_monitor/bin/python3

MON_RESPAWN=true
MON_TOPIC_PREFIX=/strawberry/consumption
MON_LOG_LEVEL=INFO

# Feature toggles
MON_CPU_ENABLED=true
MON_MEMORY_ENABLED=true
MON_GPU_ENABLED=true
MON_SPIKES_ENABLED=true

# Rates and windows
MON_PUBLISH_RATE_HZ=5.0
MON_WINDOW_SEC=1.0

# Advanced toggles
MON_ENABLE_GPU_PROCESSES=false
MON_ENABLE_POWER_METRICS=true

# Spike detector thresholds
MON_CPU_TOTAL_PERCENT_THRESHOLD=85.0
MON_CPU_CORE_PERCENT_THRESHOLD=95.0
MON_MEM_USED_PERCENT_THRESHOLD=90.0
MON_GPU_UTIL_PERCENT_THRESHOLD=90.0
MON_GPU_MEM_UTIL_PERCENT_THRESHOLD=90.0
MON_SPIKE_MIN_DURATION_SEC=0.5
MON_SPIKE_CLEAR_HYSTERESIS_PERCENT=5.0

# ==========================
# Stresstest launcher args
# ==========================

# Absolute Python path for stresstest venv used by compose.
# WARNING: Changing this may break GPU backends resolution for stress tests.
# Keep in sync with image layout.
#STRESS_VENV_PATH=/home/haru/haru_ws/install/strawberry_resource_monitor/share/strawberry_resource_monitor/venv_stresstest/bin/python3

STRESS_DURATION=30.0

# Which stresstest processes to run
STRESS_RUN_CPU=false
STRESS_RUN_MEMORY=false
STRESS_RUN_GPU=true

# CPU stress params
STRESS_CPU_WORKERS=2
STRESS_CPU_DUTY=1.0

# Memory stress params
STRESS_MEM_TARGET_PERCENT=60.0
STRESS_MEM_TARGET_GB=0.0
STRESS_MEM_RAMP_SEC=5.0
STRESS_MEM_CHUNK_MB=128

# GPU stress params
STRESS_GPU_BACKEND=auto
STRESS_GPU_TARGET_PERCENT=50.0
STRESS_GPU_TARGET_GB=0.0
STRESS_GPU_CHUNK_MB=256
STRESS_GPU_DEVICE=0